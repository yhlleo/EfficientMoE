basic:
  exp_name: 000_DSMoE_S_E16_Flow
  results_dir: exps/
  data_path: /path/to/imagenet/train

  global_seed: 1234
  epochs: 1000 
  log_every: 100
  ckpt_every: 50000
  rf: True
  rf_ori: False

  accum_iter: 1
  clip_grad_norm:    # set None to disable

  image_size: 256
  global_batch_size: 512
  num_workers: 16

  timestep_start: 0 
  timestep_end: 1000

  vae_path: stabilityai/sd-vae-ft-mse

  #dataset_config:
  #  target: dataset.dataset_cache.CachedFolder
  #  params:
  #    root: cache/


model:
  ckpt:
  target: models.models_DSMoE.DiT
  params:
    input_size: 32
    num_classes: 1000
    patch_size: 2
    depth: 10
    hidden_size: 384
    num_heads: 6
    mlp_ratio: 4
    use_swiglu: false
    rope_type: 2d
    use_sinks: false
    sliding_window: 0
    enable_gqa: false
    norm_type: layernorm
    MoE_config:
      num_experts: 16
      hidden_size: 384
      moe_intermediate_size: 768
      n_group: 2
      topk_group: 2
      num_experts_per_tok: 2
      routed_scaling_factor: 2.0
      capacity: 1
      init_MoeMLP: false
      interleave: true
      skip_first2: false
      skip_last2: false
      use_shared_expert: true
    CapacityPred_loss_weight: 1

optim:
  base_learning_rate: 0.0001
  weight_decay: 0
  betas: [0.9, 0.999]


lr_sheduler:
  warmup:
  train_epoch:



